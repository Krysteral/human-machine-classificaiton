{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Instruction\n",
        "- Step 1: check either the \"Blue Team Template\" or \"Red Team Template\" section, depending on your team's assignment. These templates describe the general abstract classes of the neural text DETECTOR and ATTACKER. These classes show you the inner workings of the detector and the attacker. However, in this template, there are a few functions that have not yet fully implemented such as how the detector will detect neural texts and how the attacker will attack a detector. This leads to Step 2 below.\n",
        "- Step 2; check either the \"Example Blue Team\" or \"Example Red Team\" section, depending on your team's assignment. These sections describe examples of how to (1) inhereit the parent template of DETECTOR and ATTACKER and (2) where you need to define the actual mechanism by which your detector and attacker will exercise. What you then need to do is, to study these examples, and define your own \"child\" abstract class by inheriting the corresponding parent template (e.g., RedBlueModelWrapper for Blue team or RedBlueAttackerWrapper for Red team).\n",
        "- Step 3: check out the example code on how you can initialize an instance (a detector or an attacker) of your own abstract class and validate that your instance is working probably.\n",
        "- Step 4: submit your code (including all the library imports and your own inherented abstract class definition) to blackboard as a single Python file or a Jupyter notebook file. Please make sure you document your code so that I can follow and make sure it runs on my computer."
      ],
      "metadata": {
        "id": "2ntCzwepADFg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ADMIN"
      ],
      "metadata": {
        "id": "kzSe8Kk2u_4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Library"
      ],
      "metadata": {
        "id": "lJgTK1Avi_-5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjyIlgHrHQj-"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install accelerate -U\n",
        "!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textattack"
      ],
      "metadata": {
        "id": "L66lKhhlwcnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time"
      ],
      "metadata": {
        "id": "K4Wejb82m4wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Blue Team Template"
      ],
      "metadata": {
        "id": "y4gq5GAYrtl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RedBlueModelWrapper:\n",
        "  def __init__(self):\n",
        "    # TODO\n",
        "    # IMPORT ALL IMPORTANT LIBRARIES HERE\n",
        "    # INITIALIZE AND LOAD YOUR MODEL, TOKENIZER\n",
        "    # AND OTHER NECCESSARY COMPONENTS HERE IF NEEDED\n",
        "    self.total_queries = 0\n",
        "    self.TIME_DURATION_ATTEMPTS = 20\n",
        "    self.query_time = []\n",
        "\n",
        "  def _query(self, text: str):\n",
        "    # TODO\n",
        "    # PREDICTION OF YOUR MODEL HERE ON THE INPUT TEXT ``text''\n",
        "    # MUST RETURN A PREDICTION PROBABILITY VECTOR IN NUMPY\n",
        "    # THIS VECTOR SHOULD HAVE SHAPE (2,),e.g., array([0.79184294, 0.20815705])\n",
        "    # THE FIRST COMPONENT IS THE PROBABILITY THE TEXT IS WRITTEN BY HUMAN\n",
        "    # THE SECOND COMPONENT IS THE PROBABILITY THE TEXT IS GENERATED BY MACHINE\n",
        "    # ALL PROBABILITIES NEED TO BE SUMED TO 1.0\n",
        "    raise NotImplementedError\n",
        "\n",
        "  def __call__(self, text: str):\n",
        "    if len(self.query_time) < self.TIME_DURATION_ATTEMPTS:\n",
        "      start_time = time.time()\n",
        "\n",
        "    probs = self._query(text)\n",
        "    assert probs.shape == (2,)\n",
        "    assert np.abs(np.sum(probs) - 1.0) < 0.001\n",
        "\n",
        "    if len(self.query_time) < self.TIME_DURATION_ATTEMPTS:\n",
        "      end_time = time.time()\n",
        "      duration = end_time - start_time\n",
        "      self.query_time.append(duration)\n",
        "\n",
        "    self.increase_query()\n",
        "    return probs\n",
        "\n",
        "  def increase_query(self):\n",
        "    self.total_queries += 1\n",
        "\n",
        "  def reset_query(self):\n",
        "    self.total_queries = 0.0\n",
        "\n",
        "  def average_time(self):\n",
        "    return np.mean(self.query_time)"
      ],
      "metadata": {
        "id": "ciPv0Pw5jJvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Red Team Template"
      ],
      "metadata": {
        "id": "_z94uI4ZrwIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RedBlueAttackerWrapper:\n",
        "  def __init__(self, target_model: RedBlueModelWrapper):\n",
        "    # TODO\n",
        "    # IMPORT ALL IMPORTANT LIBRARIES HERE\n",
        "    # INITIALIZE AND LOAD YOUR ATTACKER\n",
        "    # AND OTHER NECCESSARY COMPONENTS HERE IF NEEDED\n",
        "    self.pairs = []\n",
        "    self.TIME_DURATION_ATTEMPTS = 20\n",
        "    self.attack_time = []\n",
        "\n",
        "  def _query(self, text: str):\n",
        "    # TODO\n",
        "    # ATTACK MECHANISM OF YOUR MODEL: ATTACK ``model'' ON ``text''\n",
        "    # MUST RETURN THE ADVERSARIAL EXAMPLE OF THE TEXT\n",
        "    raise NotImplementedError\n",
        "\n",
        "  def __call__(self, text: str):\n",
        "    if len(self.attack_time) < self.TIME_DURATION_ATTEMPTS:\n",
        "      start_time = time.time()\n",
        "\n",
        "    adv_text = self._query(text)\n",
        "    assert type(adv_text) == str\n",
        "\n",
        "    if len(self.attack_time) < self.TIME_DURATION_ATTEMPTS:\n",
        "      end_time = time.time()\n",
        "      duration = end_time - start_time\n",
        "      self.attack_time.append(duration)\n",
        "\n",
        "    self.pairs.append((text, adv_text))\n",
        "\n",
        "    return adv_text\n",
        "\n",
        "  def average_time(self):\n",
        "    return np.mean(self.attack_time)"
      ],
      "metadata": {
        "id": "UL4CugNFsAEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Blue Team"
      ],
      "metadata": {
        "id": "n6zq2sTCkRKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size for training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=validation_dataset      # evaluation dataset\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "THY-bj0brp90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()\n"
      ],
      "metadata": {
        "id": "TY9rCVIarq4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inherit the main RedBlueModelWrapper class to your own model classs\n",
        "# EACH TEAM WILL THEN HAVE THEIR OWN ABSTRACT CLASS\n",
        "# E.G., RedBlueModelWrapper_Team0 FOR TEAM #0\n",
        "# E.G., RedBlueModelWrapper_Team1 FOR TEAM #1\n",
        "# E.G., RedBlueModelWrapper_Team2 FOR TEAM #2\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from transformers import pipeline\n",
        "class RedBlueModelWrapper_Team1(RedBlueModelWrapper):\n",
        "  def __init__(self):\n",
        "    # TODO\n",
        "    # IMPORT ALL IMPORTANT LIBRARIES HERE\n",
        "    # AND OTHER NECCESSARY COMPONENTS HERE IF NEEDED\n",
        "    super(RedBlueModelWrapper_Team1, self).__init__() # THIS LINE IS IMPORTANT AND MUST BE PLACED HERE\n",
        "\n",
        "    self.tokenizer_gpt2 = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "    self.model_gpt2 = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "    self.tokenizer_bert = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    self.model_bert = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "    self.tokenizer_roberta = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "    self.model_roberta = RobertaForSequenceClassification.from_pretrained(\"roberta-base\")\n",
        "\n",
        "    self.total_queries = 0\n",
        "    self.TIME_DURATION_ATTEMPTS = 20\n",
        "    self.query_time = []\n",
        "\n",
        "  def _query(self, text: str):\n",
        "    # TODO\n",
        "    # PREDICTION OF YOUR MODEL HERE ON THE INPUT TEXT ``text''\n",
        "    # MUST RETURN A PREDICTION PROBABILITY VECTOR IN NUMPY\n",
        "    # THIS VECTOR SHOULD HAVE SHAPE (2,),e.g., array([0.79184294, 0.20815705])\n",
        "    # THE FIRST COMPONENT IS THE PROBABILITY THE TEXT IS WRITTEN BY HUMAN\n",
        "    # THE SECOND COMPONENT IS THE PROBABILITY THE TEXT IS GENERATED BY MACHINE\n",
        "    # ALL PROBABILITIES NEED TO BE SUMED TO 1.0\n",
        "\n",
        "    # Prepare input for GPT-2\n",
        "    inputs_gpt2 = self.tokenizer_gpt2(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    # Prepare input for BERT\n",
        "    inputs_bert = self.tokenizer_bert(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    # Prepare input for RoBERTa\n",
        "    inputs_roberta = self.tokenizer_roberta(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "    # Get predictions from each model\n",
        "    with torch.no_grad():\n",
        "        outputs_gpt2 = self.model_gpt2(**inputs_gpt2)\n",
        "        outputs_bert = self.model_bert(**inputs_bert)\n",
        "        outputs_roberta = self.model_roberta(**inputs_roberta)\n",
        "\n",
        "    # Process the logits and get probabilities (assuming binary classification for BERT and RoBERTa)\n",
        "    # Assuming index_human and index_machine are the indices for \"human-written\" and \"machine-written\"\n",
        "\n",
        "    softmax_probs_gpt2 = torch.softmax(outputs_gpt2.logits, dim=-1).squeeze()\n",
        "    softmax_probs_bert = torch.softmax(outputs_bert.logits, dim=-1).squeeze()\n",
        "    softmax_probs_roberta = torch.softmax(outputs_roberta.logits, dim=-1).squeeze()\n",
        "\n",
        "    index_human = 0  # Example index for \"human-written\"\n",
        "    index_machine = 1  # Example index for \"machine-written\"\n",
        "\n",
        "    # Extract these probabilities from the tensor\n",
        "    reduced_probs_gpt2 = softmax_probs_gpt2[:, [index_human, index_machine]]\n",
        "    # Using only the first example from softmax_probs_gpt2 to match others\n",
        "    softmax_probs_gpt2 = softmax_probs_gpt2[0:1, [index_human, index_machine]]\n",
        "\n",
        "    # Check if we need to unsqueeze the tensors\n",
        "    if softmax_probs_gpt2.ndim == 1:\n",
        "        softmax_probs_gpt2 = softmax_probs_gpt2.unsqueeze(0)\n",
        "    if softmax_probs_bert.ndim == 1:\n",
        "        softmax_probs_bert = softmax_probs_bert.unsqueeze(0)\n",
        "    if softmax_probs_roberta.ndim == 1:\n",
        "        softmax_probs_roberta = softmax_probs_roberta.unsqueeze(0)\n",
        "\n",
        "    # Checking output size\n",
        "    # print(softmax_probs_gpt2, softmax_probs_bert, softmax_probs_roberta)\n",
        "    # print(softmax_probs_gpt2.shape)\n",
        "    # print(softmax_probs_bert.shape)\n",
        "    # print(softmax_probs_roberta.shape)\n",
        "\n",
        "    # Average the probabilities from each model\n",
        "    avg_probs = (softmax_probs_gpt2 + softmax_probs_bert + softmax_probs_roberta) / 3\n",
        "\n",
        "    # Extract the probabilities for the \"human-written\" class\n",
        "    human_prob = avg_probs[0, 0].mean().item()\n",
        "    # Extract the probabilities for the \"machine-generated\" class\n",
        "    machine_prob = avg_probs[0, 1].mean().item()\n",
        "\n",
        "    # Normalize the probabilities\n",
        "    total_prob = human_prob + machine_prob\n",
        "    human_prob /= total_prob\n",
        "    machine_prob /= total_prob\n",
        "\n",
        "    return np.array([human_prob, machine_prob])"
      ],
      "metadata": {
        "id": "HP1m4XRWlCKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize the model\n",
        "detector_team1 = RedBlueModelWrapper_Team1()\n",
        "\n",
        "test_examples = [\n",
        "    \"the president biden is in the usa\",\n",
        "    \"the president biden is in vietnam\",\n",
        "    \"the president biden is in brazill\",\n",
        "    \"Donald Trump won in Georgia\",\n",
        "    \"Don@ld Trump won in Georgia\",\n",
        "    \"The President Joe Biden is in the USA\"\n",
        "]\n",
        "\n",
        "# inference or query the model\n",
        "for text in test_examples:\n",
        "  probs = detector_team1(text)\n",
        "  print(probs)\n",
        "  print(text, probs)\n",
        "\n",
        "# check the total number of queries made to the model\n",
        "print(\"total queries=\", detector_team1.total_queries)\n",
        "\n",
        "# check the average query time\n",
        "print(\"avg query time=\", detector_team1.average_time())"
      ],
      "metadata": {
        "id": "tyeAbmeulsUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Red Team"
      ],
      "metadata": {
        "id": "MqdNXcMHkS4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inherit the main RedBlueAttackerWrapper class to your own model classs\n",
        "# EACH TEAM WILL THEN HAVE THEIR OWN ABSTRACT CLASS\n",
        "# E.G., RedBlueAttackerWrapper_Team0 FOR TEAM #0\n",
        "# E.G., RedBlueAttackerWrapper_Team1 FOR TEAM #1\n",
        "# E.G., RedBlueAttackerWrapper_Team2 FOR TEAM #2\n",
        "\n",
        "class RedBlueAttackerWrapper_Team0(RedBlueAttackerWrapper):\n",
        "  def __init__(self, target_model: RedBlueModelWrapper):\n",
        "    super(RedBlueAttackerWrapper_Team0, self).__init__(target_model) # THIS LINE IS IMPORTANT AND MUST BE PLACED HERE\n",
        "\n",
        "    self.target_model = target_model\n",
        "    self.transformation = {\n",
        "        'e': '3',\n",
        "        'o': '0',\n",
        "        'a': '@',\n",
        "        'b': '6',\n",
        "        'l': '1'\n",
        "    }\n",
        "    self.prob = 0.3\n",
        "\n",
        "  def _query(self, text):\n",
        "    # a simple attack algorithm where we iteratively perturb one character at a time\n",
        "    # you can use more complex framework like textattack or openattack\n",
        "\n",
        "    text2 = list(text)\n",
        "    org_prob = self.target_model(text)\n",
        "    org_pred = np.argmax(org_prob)\n",
        "\n",
        "    for i, char in enumerate(text2):\n",
        "      if char in self.transformation and np.random.choice([False, True], p=[1-self.prob, self.prob]):\n",
        "        text2[i] = self.transformation[char]\n",
        "        adv_text = \"\".join(text2)\n",
        "        new_pred = np.argmax(self.target_model(adv_text))\n",
        "\n",
        "        if new_pred != org_pred:\n",
        "          break #stop when the prediction changes\n",
        "\n",
        "    return adv_text"
      ],
      "metadata": {
        "id": "PBOGheMYt8zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attacker_team0 = RedBlueAttackerWrapper_Team0(detector_team0)\n",
        "\n",
        "attacker_team0(\"hello this is the president biden\")\n",
        "\n",
        "# list all attacked texts\n",
        "for pair in attacker_team0.pairs:\n",
        "  print(pair)\n",
        "\n",
        "# calculate average attack time\n",
        "print(\"average attack time=\", attacker_team0.average_time()/len(attacker_team0.pairs))"
      ],
      "metadata": {
        "id": "aifTPvkmwVDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Competition"
      ],
      "metadata": {
        "id": "QePsbs-G1ZH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "vSdii34S2rn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "competition_texts = [\n",
        "    (\"Live updates: They want him to make the ex-president pay a total of $3,000 for social media posts that allegedly violated his order\", 0),\n",
        "    (\"Israeli war cabinet reviewed military plans for a potential response against Iran, but itâ€™s unclear if there was a decision\", 0),\n",
        "    (\"Biden condemns Iranâ€™s attack in a call with King Abdullah of Jordan\", 0),\n",
        "    (\"Biden tells Netanyahu US will not participate in any counter-strike against Iran\", 0),\n",
        "    (\"Biden Calls for National Unity in Speech Addressing Recent Social Challenges\", 1),\n",
        "    (\"President Biden Signs Executive Order Increasing Federal Support for Mental Health Services\",  1),\n",
        "    (\"Biden's Education Initiative Seeks to Increase Funding for Public Schools and Teacher Salaries\",  1),\n",
        "    (\"White House Confirms Biden's Upcoming Visit to Asia to Strengthen Alliances and Trade Agreements\",  1),\n",
        "    (\"President Biden Advocates for Stricter Gun Control Measures in Wake of Recent Shootings\",  1),\n",
        "    (\"Biden Administration Announces Breakthrough in Bi-partisan Infrastructure Deal\", 1)\n",
        "]\n",
        "\n",
        "texts = [a[0] for a in competition_texts]\n",
        "labels = [a[1] for a in competition_texts]\n",
        "\n",
        "detector_team0 = RedBlueModelWrapper_Team0()\n",
        "attacker_team0 = RedBlueAttackerWrapper_Team0(detector_team0)\n",
        "\n",
        "preds = []\n",
        "for text in texts:\n",
        "  pred = detector_team0(text)\n",
        "  preds.append(np.argmax(pred))\n",
        "print(classification_report(labels, preds))\n",
        "\n",
        "atk_preds = []\n",
        "for text in texts:\n",
        "  adv_text = attacker_team0(text)\n",
        "  adv_pred = detector_team0(text)\n",
        "  atk_preds.append(np.argmax(adv_pred))\n",
        "print(classification_report(labels, atk_preds))"
      ],
      "metadata": {
        "id": "nALxm5Fv1dnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PARTICIPANTS"
      ],
      "metadata": {
        "id": "FFrFaUpZvC_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Blue Teams"
      ],
      "metadata": {
        "id": "PwAfWCA-jpxx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Team 1"
      ],
      "metadata": {
        "id": "V9LmtlrWjuZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Team 7"
      ],
      "metadata": {
        "id": "QtQ9npwOj3JS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Team 8"
      ],
      "metadata": {
        "id": "UO1RLSPqj4Nh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Team 9"
      ],
      "metadata": {
        "id": "6LL2Y4m4j5Hl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Team 10"
      ],
      "metadata": {
        "id": "YyWcm4Stj59V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Red Teams"
      ],
      "metadata": {
        "id": "QIjJQgAhjslx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Team 2"
      ],
      "metadata": {
        "id": "pwk0Zegzj9nb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Team 3"
      ],
      "metadata": {
        "id": "lEtm67Yzj_Bk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Team 4"
      ],
      "metadata": {
        "id": "T6_l6q8skALy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Team 5"
      ],
      "metadata": {
        "id": "9fQmJxY4kBsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Team 6"
      ],
      "metadata": {
        "id": "_tfgJIlIkCnp"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "_z94uI4ZrwIz",
        "MqdNXcMHkS4g",
        "QePsbs-G1ZH4",
        "PwAfWCA-jpxx",
        "QIjJQgAhjslx"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}